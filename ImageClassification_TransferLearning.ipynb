{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport os\nimport tensorflow as tf\nimport numpy as np\n\n# Set the seed for random operations. \n# This let our experiments to be reproducible. \nSEED = 1234\ntf.random.set_seed(SEED)  \n\n# Set GPU memory growth \n# Allows to only as much GPU memory as needed\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# ImageDataGenerator\n# ------------------\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\napply_data_augmentation = True\n\n# Create training ImageDataGenerator object\nif apply_data_augmentation:\n    train_data_gen = ImageDataGenerator(rotation_range=30,\n                                        width_shift_range=0.2,\n                                        height_shift_range=0.2,\n                                        brightness_range=(0.6,1),\n                                        channel_shift_range=150,\n                                        shear_range=0.2,\n                                        zoom_range=0.2,\n                                        horizontal_flip=True,\n                                        vertical_flip=True,\n                                        fill_mode='nearest',\n                                        rescale=1./255)\nelse:\n    train_data_gen = ImageDataGenerator(rescale=1./255)\n\n# Create validation and test ImageDataGenerator objects\nvalid_data_gen = ImageDataGenerator(rescale=1./255)\n#test_data_gen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil, random, json\n\n#delete file that fill the memory\nuseless_path = '/kaggle/working/classification_experiments'\nif os.path.exists(useless_path):\n    shutil.rmtree(useless_path)\n\n#check if the tmp folder exist\npath = '/kaggle/working/tmp'\nif os.path.exists(path):\n    shutil.rmtree(path)\nif not os.path.exists(path):\n    os.mkdir(path)\nif not os.path.exists(path+'/training'):\n    os.mkdir(path+'/training')\nif not os.path.exists(path+'/validation'):\n    os.mkdir(path+'/validation')\n\n# Source path \nsource = \"/kaggle/input/ann-and-dl-image-classification/Classification_Dataset/training\"\n\n# Destination path \ndest_train = path+'/training'\ndest_valid = path+'/validation'\n\n# dictionary with the format shown in the Evaluation tab\ndataset_split = {}  \ndataset_split[\"training\"] = {}\ndataset_split[\"validation\"] = {}\n\n#create train and validation into the tmp folder\nfor folder in os.listdir(source):\n    if not os.path.exists(dest_train+'/'+folder):\n        os.mkdir(dest_train+'/'+folder)\n    if not os.path.exists(dest_valid+'/'+folder):\n        os.mkdir(dest_valid+'/'+folder)\n    \n    dataset_split[\"training\"][folder] = []         # create the list of images used in training set for each class\n    dataset_split[\"validation\"][folder] = []         # create the list of images used in validation set for each class\n    cl = source+'/'+folder                             # create path of the class\n    files = os.listdir(cl)                            # list of files for the class\n    random.shuffle(files)\n    #create training set randomly\n    for i in range(int(len(files)*0.8)):\n        dest = shutil.copy(cl+'/'+files[i], dest_train+'/'+folder+'/'+files[i])    # copy an image in the training set\n        dataset_split[\"training\"][folder].append(files[i])           # insert name of file used in training set\n    #create validation set randomly\n    for j in range(i+1, len(files)):\n        dest = shutil.copy(cl+'/'+files[j], dest_valid+'/'+folder+'/'+files[j])    # copy an image in the validation set\n        dataset_split[\"validation\"][folder].append(files[j])           # insert name of file used in validation set\n\n\n# create the json file using the dictionary dataset_split\nwith open('dataset_split.json', 'w') as fp:\n    json.dump(dataset_split, fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create generators to read images from dataset directory\n# -------------------------------------------------------\nfrom collections import Counter\n\ndataset_dir = '/kaggle/working/tmp'\n\n# Batch size\nbs = 8\n\n# img shape\nimg_h = 256\nimg_w = 256\n\nnum_classes = 20\n\nclasses = ['owl',              # 0\n           'galaxy',           # 1\n           'lightning',        # 2\n           'wine-bottle',      # 3\n           't-shirt',          # 4\n           'waterfall',        # 5\n           'sword',            # 6\n           'school-bus',       # 7\n           'calculator',       # 8\n           'sheet-music',      # 9\n           'airplanes',        # 10\n           'lightbulb',        # 11\n           'skyscraper',       # 12\n           'mountain-bike',    # 13\n           'fireworks',        # 14\n           'computer-monitor', # 15\n           'bear',             # 16\n           'grand-piano',      # 17\n           'kangaroo',         # 18\n           'laptop']           # 19\n\n# Training\ntraining_dir = os.path.join(dataset_dir, 'training')\ntrain_gen = train_data_gen.flow_from_directory(training_dir,\n                                               batch_size=bs,\n                                               target_size=(img_h, img_w),\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=True,\n                                               seed=SEED)  # targets are directly converted into one-hot vectors\n\n# compute the class weights in order to balance loss during training\ncounter = Counter(train_gen.classes)                          \nmax_val = float(max(counter.values()))       \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n#print(class_weights)\n\n\n# Validation\nvalidation_dir = os.path.join(dataset_dir, 'validation')\nvalid_gen = valid_data_gen.flow_from_directory(validation_dir,\n                                               batch_size=bs, \n                                               target_size=(img_h, img_w),\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=False,\n                                               seed=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataset objects\n# ----------------------\n\n# Training\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n\ntrain_dataset = train_dataset.repeat()\n\n# Validation\n# ----------\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n\n# Repeat\nvalid_dataset = valid_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRANSFER LEARNING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Model\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\n\n#resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# VGG16\n#vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n#vgg = MobileNet(weights='imagenet',include_top=False)\n\n# InceptionV3\ninception = tf.keras.applications.InceptionV3(weights='imagenet', \n                                include_top=False, \n                                input_shape=(img_h, img_w,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vgg.summary()\n#vgg.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# freeze layers in VGG16\nfinetuning = True\nif finetuning:\n    freeze_until = 15\n    \n    for layer in vgg.layers[:freeze_until]:\n        layer.trainable = False\nelse:\n    vgg.trainable = False\n'''\n\n# freeze layers in Inception\ncount = 1\nfor layer in inception.layers:\n    if count < 260:\n        layer.trainable = False\n    else:\n        layer.trainable = True\n    count = count + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# model for Transfer Learning done with VGG16\nmodel = tf.keras.Sequential()\nmodel.add(vgg)\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(512, activation='relu', input_dim=(img_h, img_w, 3)))\nmodel.add(tf.keras.layers.Dense(units=num_classes, activation='softmax')) \n'''\n\n# model for Transfer Learning done with Inception\nmodel = tf.keras.models.Sequential()\nmodel.add(inception)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n\n# Visualize created model as a table\nmodel.summary()\n\n# Visualize initialized weights\n#model.weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen.class_indices","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare the model for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization params\n# -------------------\n\n# Loss\nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# learning rate\nlr = 2e-5\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n# -------------------\n\n# Validation metrics\n# ------------------\n\nmetrics = ['accuracy']\n# ------------------\n\n# Compile Model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom datetime import datetime\n\n# from tensorflow.compat.v1 import ConfigProto\n# from tensorflow.compat.v1 import InteractiveSession\n\n# config = ConfigProto()\n# config.gpu_options.allow_growth = True\n# session = InteractiveSession(config=config)\n\n# Get current working directory\ncwd = os.getcwd()\n\nexps_dir = os.path.join(cwd, 'classification_experiments')\nif not os.path.exists(exps_dir):\n    os.makedirs(exps_dir)\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\n\nmodel_name = 'CNN'\n\nexp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n    \n\ncallbacks = []\n'''\n# Model checkpoint\n# ----------------\nckpt_dir = os.path.join(exp_dir, 'ckpts')\nif not os.path.exists(ckpt_dir):\n    os.makedirs(ckpt_dir)\n    \nckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n                                                   save_weights_only=True)  # False to save the model directly\ncallbacks.append(ckpt_callback)\n\n# Visualize Learning on Tensorboard\n# ---------------------------------\ntb_dir = os.path.join(exp_dir, 'tb_logs')\nif not os.path.exists(tb_dir):\n    os.makedirs(tb_dir)\n\n# By default shows losses and metrics for both training and validation\ntb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n                                             profile_batch=0,\n                                             histogram_freq=1)  # if 1 shows weights histograms\ncallbacks.append(tb_callback)\n\n# Early Stopping\n# --------------\nearly_stop = False\nif early_stop:\n    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=10)\n    callbacks.append(es_callback)\n'''\n\nmodel.fit(x=train_dataset,\n          epochs=30,  #### set repeat in training dataset\n          steps_per_epoch=len(train_gen),\n          validation_data=valid_dataset,\n          validation_steps=len(valid_gen),\n          class_weight=class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#------ TEST --------\n\nfrom PIL import Image\nfrom matplotlib.pyplot import imshow\n\n# path of images to test\ntest_dir = '/kaggle/input/ann-and-dl-image-classification/Classification_Dataset/test'\n\nresults = {}\n\nfor img_name in os.listdir(test_dir):\n    img_path = os.path.join(test_dir, img_name)\n\n    img = tf.io.read_file(img_path)\n    #image = Image.open(str(img_path))\n\n    img = tf.image.decode_jpeg(img, channels=3)\n    img.set_shape([None, None, 3])\n    img = tf.image.resize(img, (img_h, img_w))\n    img /= 255\n    #imshow(np.asarray(img))\n    img = np.expand_dims(img, 0) # make 'batch' of 1\n    \n    # compute the prediction for each class\n    pred = model.predict(img)\n    \n    # take the predicted class\n    y = pred.argmax(axis=-1)[0]\n    \n    # upload on a dictionary the image with its predicted label\n    results[img_name] = y\n\n\n#print(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the predictions in a .csv file\n\ndef create_csv(results, results_dir='./'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')\n\ncreate_csv(results)\n            ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
