{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Question Answering\n",
    "We split the dataset: 80% train set and 20% validation set. The batch size is set to 128 to speed up a little bit the training part, same thing for the epochs that are only 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "COMMIT = False\n",
    "\n",
    "if COMMIT:\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import cv2\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    imgs_path = \"/kaggle/input/ann-and-dl-vqa/dataset_vqa/train\"\n",
    "    train_json_path = \"/kaggle/input/ann-and-dl-vqa/dataset_vqa/train_data.json\"\n",
    "    test_json_path = \"/kaggle/input/ann-and-dl-vqa/dataset_vqa/test_data.json\"\n",
    "    \n",
    "    SEED = 1234\n",
    "    DATASET_SPLIT = 0.8\n",
    "    img_h = 128\n",
    "    img_w = 128\n",
    "    BATCH_SIZE = 128\n",
    "    \n",
    "    classes = {'0': 0,\n",
    "               '1': 1,\n",
    "               '10': 2,\n",
    "               '2': 3,\n",
    "               '3': 4,\n",
    "               '4': 5,\n",
    "               '5': 6,\n",
    "               '6': 7,\n",
    "               '7': 8,\n",
    "               '8': 9,\n",
    "               '9': 10,\n",
    "               'no': 11,\n",
    "               'yes': 12}\n",
    "    \n",
    "    N_CLASSES = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMIT:\n",
    "    # ----------------------TRAIN THE TOKENIZER VOCABULARY----------------------\n",
    "    if 'tokenizer' not in globals():        # only if it does not exists yet\n",
    "        # Use the Tokenizer to transform the text (questions) into sequence\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "        with open(train_json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            data = data['questions']\n",
    "\n",
    "            for question in data:\n",
    "                quest = question['question'].split(\" \")\n",
    "                for i in range(len(quest)):\n",
    "                    quest[i] = quest[i].replace(\"?\", \"\")\n",
    "                #print(quest)\n",
    "\n",
    "                # Updates internal vocabulary based on the questions of the dataset\n",
    "                tokenizer.fit_on_texts(quest)            \n",
    "        f.close()\n",
    "    words_number = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0573b59b21ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     def __init__(self, list_IDs, image_path, train_input_questions, max_length, to_fit=True,\n\u001b[1;32m      4\u001b[0m                  batch_size=16, dim=(100, 150), n_channels=3, n_classes=13, shuffle=True):\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_IDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, list_IDs, image_path, train_input_questions, max_length, to_fit=True,\n",
    "                 batch_size=16, dim=(100, 150), n_channels=3, n_classes=13, shuffle=True):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.train_input_questions = train_input_questions\n",
    "        self.image_path = image_path\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.img_h = dim[0]\n",
    "        self.img_w = dim[1]\n",
    "        self.max_length = max_length\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(list_IDs_temp)\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(list_IDs_temp)\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_X(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        X2 = np.empty((self.batch_size, self.max_length))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = self._load_image(self.image_path[ID], self.img_w, self.img_h)\n",
    "            X2[i,] = (self.train_input_questions[ID]).tolist()\n",
    "        ole = [X2, X]\n",
    "        \n",
    "        return ole\n",
    "\n",
    "    def _generate_y(self, list_IDs_temp):\n",
    "        y = np.empty((self.batch_size, 1), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            y[i] = self.list_IDs[ID]\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _load_image(self, image_path, img_w, img_h):\n",
    "        if self.to_fit:\n",
    "            image = cv2.imread(\"/kaggle/input/ann-and-dl-vqa/dataset_vqa/train/\" + image_path)\n",
    "        else:\n",
    "            image = cv2.imread(\"/kaggle/input/ann-and-dl-vqa/dataset_vqa/test/\" + image_path)   \n",
    "        image = cv2.resize(image, (img_w, img_h))\n",
    "        image = image/ 255.\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrainJson(data, first, last):\n",
    "        images = []\n",
    "        questions = []\n",
    "        answers = []\n",
    "\n",
    "        for question in data[first:last]:\n",
    "            name = question['image_filename']\n",
    "            quest = question['question'].split(\" \")\n",
    "            for i in range(len(quest)):\n",
    "                quest[i] = quest[i].replace(\"?\", \"\")\n",
    "            ans = question['answer']\n",
    "\n",
    "            images.append(name)\n",
    "            questions.append(quest)\n",
    "            answers.append(classes[ans])\n",
    "        return images, questions, answers\n",
    "\n",
    "def readTestJson(data, first, last):\n",
    "    quest_id = []\n",
    "    images = []\n",
    "    questions = []\n",
    "\n",
    "    for question in data[first:last]:\n",
    "        qid = question['question_id']\n",
    "        name = question['image_filename']\n",
    "        quest = question['question'].split(\" \")\n",
    "        for i in range(len(quest)):\n",
    "            quest[i] = quest[i].replace(\"?\", \"\")\n",
    "        \n",
    "        quest_id.append(qid)\n",
    "        images.append(name)\n",
    "        questions.append(quest)\n",
    "    return images, questions, quest_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Generator\n",
    "We used a custom generator who take the couple (image, question) as input and its answer as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMIT:\n",
    "    #read train JSON file\n",
    "    with open(train_json_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        train_data = train_data['questions']\n",
    "    f.close()\n",
    "    \n",
    "    #read test JSON file\n",
    "    with open(test_json_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "        test_data = test_data['questions']\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    TOT_QUESTIONS = len(train_data)\n",
    "    TRAIN_QUESTIONS = int(TOT_QUESTIONS*DATASET_SPLIT)\n",
    "    VALID_QUESTIONS = TOT_QUESTIONS-TRAIN_QUESTIONS\n",
    "\n",
    "    #extract images, questions and answer (or quest_id) from the train and test files\n",
    "    train_images, train_questions, train_answers = readTrainJson(train_data, 0, TRAIN_QUESTIONS)\n",
    "    valid_images, valid_questions, valid_answers = readTrainJson(train_data, TRAIN_QUESTIONS, TOT_QUESTIONS)\n",
    "    test_images, test_questions, questions_id = readTestJson(test_data, 0, len(test_data))\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(train_questions)\n",
    "    max_length = max(len(sequence) for sequence in sequences)\n",
    "    train_input_questions = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(valid_questions)\n",
    "    valid_input_questions = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "    tokenizer.fit_on_texts(test_questions)\n",
    "    sequences = tokenizer.texts_to_sequences(test_questions)\n",
    "    test_input_questions = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "    words_number = len(tokenizer.word_index) + 1\n",
    "\n",
    "    training_generator = DataGenerator(train_answers, train_images, train_input_questions, max_length, batch_size=BATCH_SIZE, dim=(img_h, img_w), n_classes=N_CLASSES)\n",
    "    validation_generator = DataGenerator(valid_answers, valid_images, valid_input_questions, max_length, batch_size=BATCH_SIZE, dim=(img_h, img_w), n_classes=N_CLASSES)\n",
    "    test_generator = DataGenerator(questions_id, test_images, test_input_questions,  max_length, to_fit=False, batch_size=1, dim=(img_h, img_w), n_classes=N_CLASSES, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN & RNN\n",
    "We used the standard network provided by Keras and than we introduce some changing in order to reach a better result. For example: VGG16 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMIT:\n",
    "    # Import Keras \n",
    "    # import tensorflow as tensorflow\n",
    "    \n",
    "    INPUT_SIZE_MERGE = 64\n",
    "\n",
    "    # Define CNN for Image Input\n",
    "    base_model = tf.keras.applications.VGG16(input_shape=(img_h, img_w, 3), include_top=False, weights='imagenet')\n",
    "    for i in range(len(base_model.layers)):\n",
    "        base_model.layers[i].trainable = False\n",
    "        \n",
    "    vision_model = tf.keras.models.Sequential()\n",
    "    #vision_model.add(tf.keras.layers.Dropout(0.2))\n",
    "    #global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    vision_model.add(base_model)\n",
    "    #vision_model.add(global_average_layer)\n",
    "    vision_model.add(tf.keras.layers.Dropout(0.1))\n",
    "    vision_model.add(tf.keras.layers.Flatten())\n",
    "    vision_model.add(tf.keras.layers.Dense(INPUT_SIZE_MERGE))\n",
    "\n",
    "    image_input = tf.keras.layers.Input(shape=(img_h, img_w, 3))\n",
    "    encoded_image = vision_model(image_input)\n",
    "\n",
    "    # Define RNN for language input\n",
    "    question_input = tf.keras.layers.Input(shape=[max_length])\n",
    "    embedded_question = tf.keras.layers.Embedding(input_dim=words_number, output_dim=512, input_length=100)(question_input)\n",
    "    encoded_question = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(INPUT_SIZE_MERGE, dropout=0.1, recurrent_dropout=0.1, unroll=True))(embedded_question)\n",
    "\n",
    "    # Combine CNN and RNN to create the final model\n",
    "    merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n",
    "    output = tf.keras.layers.Dense(32)(merged)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "    output = tf.keras.layers.Dense(len(classes), activation='softmax')(output)\n",
    "    vqa_model = tf.keras.models.Model(inputs=[question_input, image_input], outputs=output)\n",
    "    \n",
    "    vision_model.summary()\n",
    "    vqa_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "We play a lot with the learning rate, optimizer and loss to improve our result but they does not seem to change a lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMIT:\n",
    "    # Optimization params\n",
    "    # -------------------\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # learning rate\n",
    "    lr = 5e-4\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr, rho=0.9)\n",
    "    # -------------------\n",
    "\n",
    "    # Validation metrics\n",
    "    # ------------------\n",
    "\n",
    "    metrics = ['accuracy']\n",
    "    # ------------------\n",
    "\n",
    "    # Compile Model\n",
    "    #vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    vqa_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMIT:\n",
    "    vqa_model.fit_generator(generator=training_generator,\n",
    "                            validation_data=validation_generator,\n",
    "                            epochs=2)\n",
    "    pred = vqa_model.predict_generator(test_generator)"
   ]
  }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    results[test_generator.list_IDs[i]] = np.argmax(pred[i])\n",
    "\n",
    "create_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
